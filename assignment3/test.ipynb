{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb1506a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge steps:\n",
      "Step 1: merged clusters: {H} and {J}, distance: 0.60\n",
      "Step 2: merged clusters: {D} and {F}, distance: 1.20\n",
      "Step 3: merged clusters: {G} and {H, J}, distance: 2.10\n",
      "Step 4: merged clusters: {A} and {B}, distance: 2.30\n",
      "Step 5: merged clusters: {E} and {D, F}, distance: 2.80\n",
      "Step 6: merged clusters: {A, B} and {D, E, F}, distance: 3.40\n",
      "Step 7: merged clusters: {I} and {G, H, J}, distance: 3.60\n",
      "Step 8: merged clusters: {C} and {A, B, D, E, F}, distance: 4.30\n",
      "Step 9: merged clusters: {G, H, I, J} and {A, B, C, D, E, F}, distance: 4.70\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "import scipy.spatial.distance as ssd\n",
    "\n",
    "# Define the distance matrix and labels\n",
    "distance_matrix = np.array([\n",
    "    [0.0, 2.3, 4.3, 8.5, 5.7, 9.7, 6.0, 7.7, 11.9, 8.3],\n",
    "    [2.3, 0.0, 5.0, 6.2, 3.4, 7.4, 6.7, 5.8, 9.6, 6.0],\n",
    "    [4.3, 5.0, 0.0, 7.6, 4.8, 8.8, 4.7, 6.8, 11.0, 7.4],\n",
    "    [8.5, 6.2, 7.6, 0.0, 2.8, 1.2, 8.1, 7.2, 4.8, 7.4],\n",
    "    [5.7, 3.4, 4.8, 2.8, 0.0, 4.0, 5.9, 5.0, 6.2, 5.2],\n",
    "    [9.7, 7.4, 8.8, 1.2, 4.0, 0.0, 8.3, 7.4, 5.0, 7.6],\n",
    "    [6.0, 6.7, 4.7, 8.1, 5.9, 8.3, 0.0, 2.1, 6.3, 2.7],\n",
    "    [7.7, 5.8, 6.8, 7.2, 5.0, 7.4, 2.1, 0.0, 4.2, 0.6],\n",
    "    [11.9, 9.6, 11.0, 4.8, 6.2, 5.0, 6.3, 4.2, 0.0, 3.6],\n",
    "    [8.3, 6.0, 7.4, 7.4, 5.2, 7.6, 2.7, 0.6, 3.6, 0.0]\n",
    "])\n",
    "\n",
    "labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\n",
    "\n",
    "condensed_dist = ssd.squareform(distance_matrix)\n",
    "\n",
    "# Perform hierarchical clustering using single linkage\n",
    "Z = linkage(condensed_dist, method='single')\n",
    "\n",
    "# Initialize clusters with individual labels\n",
    "clusters = [[label] for label in labels]\n",
    "\n",
    "# Print each merge step\n",
    "print(\"Merge steps:\")\n",
    "for step in range(Z.shape[0]):\n",
    "    cluster_idx1 = int(Z[step, 0])\n",
    "    cluster_idx2 = int(Z[step, 1])\n",
    "    distance = Z[step, 2]\n",
    "    \n",
    "    # Get the clusters to merge\n",
    "    cluster1 = clusters[cluster_idx1]\n",
    "    cluster2 = clusters[cluster_idx2]\n",
    "    \n",
    "    # Format clusters for printing\n",
    "    merged1 = ', '.join(sorted(cluster1))\n",
    "    merged2 = ', '.join(sorted(cluster2))\n",
    "    \n",
    "    print(f\"Step {step+1}: merged clusters: {{{merged1}}} and {{{merged2}}}, distance: {distance:.2f}\")\n",
    "    \n",
    "    # Merge clusters and add to the list\n",
    "    clusters.append(cluster1 + cluster2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e866fbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formula used: d(p, q) = square root of ((q1 - p1)^2 + (q2 - p2)^2)\n",
      "Euclidean Distance Matrix:\n",
      "      A     B     C     D     E     F     G     H     I     J\n",
      "A  0.00  1.70  3.11  6.19  4.03  7.05  5.80  6.53  8.63  6.96\n",
      "B  1.70  0.00  3.67  4.49  2.47  5.35  5.28  5.60  7.20  6.00\n",
      "C  3.11  3.67  0.00  7.03  4.51  7.78  3.53  4.84  7.86  5.28\n",
      "D  6.19  4.49  7.03  0.00  2.52  0.86  6.08  5.12  4.16  5.23\n",
      "E  4.03  2.47  4.51  2.52  0.00  3.30  4.17  3.81  4.75  4.11\n",
      "F  7.05  5.35  7.78  0.86  3.30  0.00  6.55  5.42  3.86  5.46\n",
      "G  5.80  5.28  3.53  6.08  4.17  6.55  0.00  1.62  5.03  1.97\n",
      "H  6.53  5.60  4.84  5.12  3.81  5.42  1.62  0.00  3.42  0.45\n",
      "I  8.63  7.20  7.86  4.16  4.75  3.86  5.03  3.42  0.00  3.14\n",
      "J  6.96  6.00  5.28  5.23  4.11  5.46  1.97  0.45  3.14  0.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "import re\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "# Question 1\n",
    "stations = np.array([\n",
    "    [0.3, 2.3], [1.1, 3.8], [2.9, 0.6], [3.5, 7.6], [3.2, 5.1],\n",
    "    [4.0, 8.3], [6.1, 2.1], [6.7, 3.6], [7.6, 6.9], [7.1, 3.8]\n",
    "])\n",
    "\n",
    "# 1a) Euclidean Distance Matrix\n",
    "# Formula: Given two points p = (p1, p2) and q = (q1, q2), the Euclidean distance d(p, q) = sqrt((q1 - p1)^2 + (q2 - p2)^2)\n",
    "euclidean_dist = squareform(pdist(stations, metric='euclidean'))\n",
    "print(\"Formula used: d(p, q) = square root of ((q1 - p1)^2 + (q2 - p2)^2)\")\n",
    "print(\"Euclidean Distance Matrix:\")\n",
    "stations_labels = list('ABCDEFGHIJ')\n",
    "df_euclidean = pd.DataFrame(euclidean_dist, columns=stations_labels, index=stations_labels)\n",
    "print(df_euclidean.round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "525f9130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Manhattan Distance Matrix:\n",
      "      A    B     C    D    E    F    G    H     I    J\n",
      "A   0.0  2.3   4.3  8.5  5.7  9.7  6.0  7.7  11.9  8.3\n",
      "B   2.3  0.0   5.0  6.2  3.4  7.4  6.7  5.8   9.6  6.0\n",
      "C   4.3  5.0   0.0  7.6  4.8  8.8  4.7  6.8  11.0  7.4\n",
      "D   8.5  6.2   7.6  0.0  2.8  1.2  8.1  7.2   4.8  7.4\n",
      "E   5.7  3.4   4.8  2.8  0.0  4.0  5.9  5.0   6.2  5.2\n",
      "F   9.7  7.4   8.8  1.2  4.0  0.0  8.3  7.4   5.0  7.6\n",
      "G   6.0  6.7   4.7  8.1  5.9  8.3  0.0  2.1   6.3  2.7\n",
      "H   7.7  5.8   6.8  7.2  5.0  7.4  2.1  0.0   4.2  0.6\n",
      "I  11.9  9.6  11.0  4.8  6.2  5.0  6.3  4.2   0.0  3.6\n",
      "J   8.3  6.0   7.4  7.4  5.2  7.6  2.7  0.6   3.6  0.0\n",
      "Formula used: d(p, q) = absolute value of (q1 - p1) + absolute value of (q2 - p2)\n"
     ]
    }
   ],
   "source": [
    "manhattan_dist = squareform(pdist(stations, metric='cityblock'))\n",
    "print(\"\\nManhattan Distance Matrix:\")\n",
    "df_manhattan = pd.DataFrame(manhattan_dist, columns=stations_labels, index=stations_labels)\n",
    "print(df_manhattan.round(2))\n",
    "print(\"Formula used: d(p, q) = absolute value of (q1 - p1) + absolute value of (q2 - p2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54caeffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed steps of hierarchical clustering (single - linkage) using Euclidean distance:\n",
      "Step 1:\n",
      "  Merged clusters: (7, 9)\n",
      "  Distance between them: 0.45\n",
      "  New cluster formed: [7, 9]\n",
      "Step 2:\n",
      "  Merged clusters: (3, 5)\n",
      "  Distance between them: 0.86\n",
      "  New cluster formed: [3, 5]\n",
      "Step 3:\n",
      "  Merged clusters: (4, 6)\n",
      "  Distance between them: 1.62\n",
      "  New cluster formed: [6, 7, 9]\n",
      "Step 4:\n",
      "  Merged clusters: (0, 1)\n",
      "  Distance between them: 1.70\n",
      "  New cluster formed: [0, 1]\n",
      "Step 5:\n",
      "  Merged clusters: (1, 5)\n",
      "  Distance between them: 2.47\n",
      "  New cluster formed: [4, 0, 1]\n",
      "Step 6:\n",
      "  Merged clusters: (2, 4)\n",
      "  Distance between them: 2.52\n",
      "  New cluster formed: [3, 5, 4, 0, 1]\n",
      "Step 7:\n",
      "  Merged clusters: (0, 3)\n",
      "  Distance between them: 3.11\n",
      "  New cluster formed: [2, 3, 5, 4, 0, 1]\n",
      "Step 8:\n",
      "  Merged clusters: (0, 1)\n",
      "  Distance between them: 3.14\n",
      "  New cluster formed: [8, 6, 7, 9]\n",
      "Step 9:\n",
      "  Merged clusters: (0, 1)\n",
      "  Distance between them: 3.53\n",
      "  New cluster formed: [2, 3, 5, 4, 0, 1, 8, 6, 7, 9]\n",
      "\n",
      "Detailed steps of hierarchical clustering (single - linkage) using Manhattan distance:\n",
      "Step 1:\n",
      "  Merged clusters: (7, 9)\n",
      "  Distance between them: 0.60\n",
      "  New cluster formed: [7, 9]\n",
      "Step 2:\n",
      "  Merged clusters: (3, 5)\n",
      "  Distance between them: 1.20\n",
      "  New cluster formed: [3, 5]\n",
      "Step 3:\n",
      "  Merged clusters: (4, 6)\n",
      "  Distance between them: 2.10\n",
      "  New cluster formed: [6, 7, 9]\n",
      "Step 4:\n",
      "  Merged clusters: (0, 1)\n",
      "  Distance between them: 2.30\n",
      "  New cluster formed: [0, 1]\n",
      "Step 5:\n",
      "  Merged clusters: (1, 3)\n",
      "  Distance between them: 2.80\n",
      "  New cluster formed: [4, 3, 5]\n",
      "Step 6:\n",
      "  Merged clusters: (3, 4)\n",
      "  Distance between them: 3.40\n",
      "  New cluster formed: [0, 1, 4, 3, 5]\n",
      "Step 7:\n",
      "  Merged clusters: (1, 2)\n",
      "  Distance between them: 3.60\n",
      "  New cluster formed: [8, 6, 7, 9]\n",
      "Step 8:\n",
      "  Merged clusters: (0, 1)\n",
      "  Distance between them: 4.30\n",
      "  New cluster formed: [2, 0, 1, 4, 3, 5]\n",
      "Step 9:\n",
      "  Merged clusters: (0, 1)\n",
      "  Distance between them: 4.70\n",
      "  New cluster formed: [8, 6, 7, 9, 2, 0, 1, 4, 3, 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fsm\\AppData\\Local\\Temp\\ipykernel_33672\\3783905731.py:56: ClusterWarning: The symmetric non-negative hollow observation matrix looks suspiciously like an uncondensed distance matrix\n",
      "  Z_euclidean = linkage(euclidean_dist, method='single')\n",
      "C:\\Users\\fsm\\AppData\\Local\\Temp\\ipykernel_33672\\3783905731.py:57: ClusterWarning: The symmetric non-negative hollow observation matrix looks suspiciously like an uncondensed distance matrix\n",
      "  Z_manhattan = linkage(manhattan_dist, method='single')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formula used for single - linkage clustering: d(Ci, Cj) = minimum distance between any point p in Ci and any point q in Cj\n"
     ]
    }
   ],
   "source": [
    "def hierarchical_clustering_steps(distance_matrix):\n",
    "    clusters = [[i] for i in range(len(stations))]\n",
    "    steps = []\n",
    "\n",
    "    while len(clusters) > 1:\n",
    "        min_distance = np.inf\n",
    "        merge_indices = None\n",
    "        for i in range(len(clusters)):\n",
    "            for j in range(i + 1, len(clusters)):\n",
    "                cluster_i = clusters[i]\n",
    "                cluster_j = clusters[j]\n",
    "                cluster_distances = []\n",
    "                for idx_i in cluster_i:\n",
    "                    for idx_j in cluster_j:\n",
    "                        cluster_distances.append(distance_matrix[idx_i, idx_j])\n",
    "                single_linkage_distance = min(cluster_distances)\n",
    "                if single_linkage_distance < min_distance:\n",
    "                    min_distance = single_linkage_distance\n",
    "                    merge_indices = (i, j)\n",
    "\n",
    "        i, j = merge_indices\n",
    "        new_cluster = clusters[i] + clusters[j]\n",
    "        del clusters[j]\n",
    "        del clusters[i]\n",
    "        clusters.append(new_cluster)\n",
    "\n",
    "        step_info = {\n",
    "            \"merged_clusters\": (merge_indices[0], merge_indices[1]),\n",
    "            \"distance\": min_distance,\n",
    "            \"new_cluster\": new_cluster\n",
    "        }\n",
    "        steps.append(step_info)\n",
    "\n",
    "    return steps\n",
    "\n",
    "\n",
    "# Euclidean clustering steps\n",
    "euclidean_steps = hierarchical_clustering_steps(euclidean_dist)\n",
    "print(\"\\nDetailed steps of hierarchical clustering (single - linkage) using Euclidean distance:\")\n",
    "for idx, step in enumerate(euclidean_steps):\n",
    "    print(f\"Step {idx + 1}:\")\n",
    "    print(f\"  Merged clusters: {step['merged_clusters']}\")\n",
    "    print(f\"  Distance between them: {step['distance']:.2f}\")\n",
    "    print(f\"  New cluster formed: {step['new_cluster']}\")\n",
    "\n",
    "# Manhattan clustering steps\n",
    "manhattan_steps = hierarchical_clustering_steps(manhattan_dist)\n",
    "print(\"\\nDetailed steps of hierarchical clustering (single - linkage) using Manhattan distance:\")\n",
    "for idx, step in enumerate(manhattan_steps):\n",
    "    print(f\"Step {idx + 1}:\")\n",
    "    print(f\"  Merged clusters: {step['merged_clusters']}\")\n",
    "    print(f\"  Distance between them: {step['distance']:.2f}\")\n",
    "    print(f\"  New cluster formed: {step['new_cluster']}\")\n",
    "\n",
    "\n",
    "Z_euclidean = linkage(euclidean_dist, method='single')\n",
    "Z_manhattan = linkage(manhattan_dist, method='single')\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "dendrogram(Z_euclidean, labels=stations_labels)\n",
    "plt.title('Euclidean Single Linkage')\n",
    "plt.subplot(1, 2, 2)\n",
    "dendrogram(Z_manhattan, labels=stations_labels)\n",
    "plt.title('Manhattan Single Linkage')\n",
    "plt.show()\n",
    "print(\"Formula used for single - linkage clustering: d(Ci, Cj) = minimum distance between any point p in Ci and any point q in Cj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f16fccbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequent Itemsets:\n",
      "Items: 0_B, Support: 0.50\n",
      "Items: 0_D, Support: 0.33\n",
      "Items: 1_A, Support: 0.50\n",
      "Items: 1_C, Support: 0.33\n",
      "Items: 2_E, Support: 0.33\n",
      "Items: 0_B, 1_A, Support: 0.33\n",
      "Items: 1_A, 2_E, Support: 0.33\n",
      "Formula used for support: Support(X) = (Number of transactions containing X) / (Total number of transactions)\n"
     ]
    }
   ],
   "source": [
    "# Question 2\n",
    "transactions = [\n",
    "    {'A', 'B', 'C'}, {'E', 'D', 'A'}, {'A', 'E'},\n",
    "    {'B', 'C'}, {'A', 'B', 'E'}, {'C', 'B', 'D'}\n",
    "]\n",
    "\n",
    "# 2a) Frequent Itemsets (Apriori Algorithm)\n",
    "# Formula: Support of an itemset X is Support(X) = (Number of transactions containing X) / (Total number of transactions)\n",
    "df = pd.get_dummies(pd.DataFrame(transactions)).fillna(0)\n",
    "frequent_itemsets = apriori(df, min_support=2/6, use_colnames=True)\n",
    "print(\"\\nFrequent Itemsets:\")\n",
    "for index, row in frequent_itemsets.iterrows():\n",
    "    items = ', '.join(row['itemsets'])\n",
    "    support = row['support']\n",
    "    print(f\"Items: {items}, Support: {support:.2f}\")\n",
    "print(\"Formula used for support: Support(X) = (Number of transactions containing X) / (Total number of transactions)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70efd557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Count support for single itemsets\n",
      "Single itemset counts: {'A': 4, 'B': 4, 'C': 3, 'E': 3, 'D': 2}\n",
      "Frequent single itemsets (min support = 2): {'A': 4, 'B': 4, 'C': 3, 'E': 3, 'D': 2}\n",
      "\n",
      "Step 3: Generate candidate itemsets of size 2\n",
      "Candidate itemsets of size 2: {('A', 'E'), ('A', 'B'), ('B', 'C'), ('C', 'D'), ('C', 'E'), ('B', 'D'), ('D', 'E'), ('A', 'C'), ('B', 'E'), ('A', 'D')}\n",
      "Candidate counts: {('A', 'E'): 3, ('A', 'B'): 2, ('B', 'C'): 3, ('C', 'D'): 1, ('C', 'E'): 0, ('B', 'D'): 1, ('D', 'E'): 1, ('A', 'C'): 1, ('B', 'E'): 1, ('A', 'D'): 1}\n",
      "Frequent candidate itemsets (min support = 2): {('A', 'E'): 3, ('A', 'B'): 2, ('B', 'C'): 3}\n",
      "\n",
      "Step 3: Generate candidate itemsets of size 3\n",
      "Candidate itemsets of size 3: {(('A', 'B'), ('A', 'E'), ('B', 'C'))}\n",
      "Candidate counts: {(('A', 'B'), ('A', 'E'), ('B', 'C')): 0}\n",
      "Frequent candidate itemsets (min support = 2): {}\n",
      "\n",
      "Frequent Itemsets (min support = 2):\n",
      "{'A'}\n",
      "{'B'}\n",
      "{'C'}\n",
      "{'E'}\n",
      "{'D'}\n",
      "{'A', 'E'}\n",
      "{'B', 'A'}\n",
      "{'B', 'C'}\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def get_frequent_itemsets(transactions, min_support):\n",
    "    # Step 1: Generate single itemsets and count their support\n",
    "    print(\"Step 1: Count support for single itemsets\")\n",
    "    itemsets = {}\n",
    "    for transaction in transactions:\n",
    "        for item in transaction:\n",
    "            if item in itemsets:\n",
    "                itemsets[item] += 1\n",
    "            else:\n",
    "                itemsets[item] = 1\n",
    "\n",
    "    print(\"Single itemset counts:\", itemsets)\n",
    "\n",
    "    # Step 2: Filter single itemsets based on min_support\n",
    "    frequent_itemsets = {item: count for item, count in itemsets.items() if count >= min_support}\n",
    "    print(\"Frequent single itemsets (min support = {}): {}\".format(min_support, frequent_itemsets))\n",
    "\n",
    "    # List to hold all frequent itemsets\n",
    "    all_frequent_itemsets = [set([item]) for item in frequent_itemsets.keys()]\n",
    "    \n",
    "    k = 2  # Start with pairs\n",
    "    while True:\n",
    "        # Step 3: Generate candidate itemsets of size k\n",
    "        print(\"\\nStep 3: Generate candidate itemsets of size {}\".format(k))\n",
    "        candidates = set()\n",
    "        for combo in combinations(frequent_itemsets.keys(), k):\n",
    "            candidates.add(tuple(sorted(combo)))\n",
    "        \n",
    "        print(\"Candidate itemsets of size {}: {}\".format(k, candidates))\n",
    "\n",
    "        # Step 4: Count support for candidates\n",
    "        candidate_counts = {candidate: 0 for candidate in candidates}\n",
    "        for transaction in transactions:\n",
    "            transaction_set = set(transaction)\n",
    "            for candidate in candidates:\n",
    "                if set(candidate).issubset(transaction_set):\n",
    "                    candidate_counts[candidate] += 1\n",
    "\n",
    "        print(\"Candidate counts:\", candidate_counts)\n",
    "\n",
    "        # Step 5: Filter candidates based on min_support\n",
    "        frequent_candidates = {candidate: count for candidate, count in candidate_counts.items() if count >= min_support}\n",
    "        print(\"Frequent candidate itemsets (min support = {}): {}\".format(min_support, frequent_candidates))\n",
    "\n",
    "        if not frequent_candidates:\n",
    "            break  # No more frequent itemsets found\n",
    "\n",
    "        # Add frequent itemsets of size k to the list\n",
    "        all_frequent_itemsets.extend([set(candidate) for candidate in frequent_candidates.keys()])\n",
    "        \n",
    "        # Update frequent_itemsets for the next iteration\n",
    "        frequent_itemsets = {item: count for item, count in frequent_candidates.items()}\n",
    "        k += 1\n",
    "\n",
    "    return all_frequent_itemsets\n",
    "\n",
    "# Example transactions\n",
    "transactions = [\n",
    "    ['A', 'B', 'C'],\n",
    "    ['E', 'D', 'A'],\n",
    "    ['A', 'E'],\n",
    "    ['B', 'C'],\n",
    "    ['A', 'B', 'E'],\n",
    "    ['C', 'B', 'D']\n",
    "]\n",
    "\n",
    "# Set minimum support\n",
    "min_support = 2\n",
    "\n",
    "# Get frequent itemsets\n",
    "frequent_itemsets = get_frequent_itemsets(transactions, min_support)\n",
    "\n",
    "# Output the results\n",
    "print(\"\\nFrequent Itemsets (min support = {}):\".format(min_support))\n",
    "for itemset in frequent_itemsets:\n",
    "    print(itemset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d9d1bca",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 2b) Association Rules\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Confidence formula: Given a rule X -> Y, Confidence(X -> Y) = Support(X U Y) / Support(X)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Lift formula: Lift(X -> Y) = Support(X U Y) / (Support(X) * Support(Y))\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m rules \u001b[38;5;241m=\u001b[39m \u001b[43massociation_rules\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfrequent_itemsets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfidence\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m rules \u001b[38;5;241m=\u001b[39m rules[rules[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupport\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.3\u001b[39m]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAssociation Rules:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\mlxtend\\frequent_patterns\\association_rules.py:129\u001b[0m, in \u001b[0;36massociation_rules\u001b[1;34m(df, num_itemsets, df_orig, null_values, metric, min_threshold, support_only, return_metrics)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# check for valid input\u001b[39;00m\n\u001b[0;32m    127\u001b[0m fpc\u001b[38;5;241m.\u001b[39mvalid_input_check(df_orig, null_values)\n\u001b[1;32m--> 129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    131\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe input DataFrame `df` containing \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe frequent itemsets is empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    132\u001b[0m     )\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# check for mandatory columns\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# 2b) Association Rules\n",
    "# Confidence formula: Given a rule X -> Y, Confidence(X -> Y) = Support(X U Y) / Support(X)\n",
    "# Lift formula: Lift(X -> Y) = Support(X U Y) / (Support(X) * Support(Y))\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.6)\n",
    "rules = rules[rules['support'] >= 0.3]\n",
    "print(\"\\nAssociation Rules:\")\n",
    "for index, row in rules.iterrows():\n",
    "    antecedent = ', '.join(row['antecedents'])\n",
    "    consequent = ', '.join(row['consequents'])\n",
    "    support = row['support']\n",
    "    confidence = row['confidence']\n",
    "    lift = row['lift']\n",
    "    print(f\"Rule: {antecedent} -> {consequent}, Support: {support:.2f}, Confidence: {confidence:.2f}, Lift: {lift:.2f}\")\n",
    "print(\"Formula used for confidence: Confidence(X -> Y) = Support of (X union Y) / Support of X\")\n",
    "print(\"Formula used for lift: Lift(X -> Y) = Support of (X union Y) / (Support of X * Support of Y)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80a78048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Single Itemsets and their Support:\n",
      "Item: A, Support: 0.67\n",
      "Item: B, Support: 0.67\n",
      "Item: C, Support: 0.50\n",
      "Item: E, Support: 0.50\n",
      "Item: D, Support: 0.33\n",
      "\n",
      "Generating Association Rules:\n",
      "\n",
      "Examining itemset: {'A'}\n",
      "\n",
      "Examining itemset: {'B'}\n",
      "\n",
      "Examining itemset: {'C'}\n",
      "\n",
      "Examining itemset: {'E'}\n",
      "\n",
      "Examining itemset: {'D'}\n",
      "\n",
      "Examining itemset: {'D', 'B'}\n",
      "  Antecedent: frozenset({'D'}), Consequent: frozenset({'B'})\n",
      "  Support(A ∪ B): 0.17, Support(A): 0.33, Confidence: 0.50\n",
      "  Antecedent: frozenset({'B'}), Consequent: frozenset({'D'})\n",
      "  Support(A ∪ B): 0.17, Support(A): 0.67, Confidence: 0.25\n",
      "\n",
      "Examining itemset: {'A', 'E'}\n",
      "  Antecedent: frozenset({'A'}), Consequent: frozenset({'E'})\n",
      "  Support(A ∪ B): 0.50, Support(A): 0.67, Confidence: 0.75\n",
      "  Rule passed: frozenset({'A'}) -> frozenset({'E'}), Support: 0.50, Confidence: 0.75\n",
      "  Antecedent: frozenset({'E'}), Consequent: frozenset({'A'})\n",
      "  Support(A ∪ B): 0.50, Support(A): 0.50, Confidence: 1.00\n",
      "  Rule passed: frozenset({'E'}) -> frozenset({'A'}), Support: 0.50, Confidence: 1.00\n",
      "\n",
      "Examining itemset: {'B', 'C'}\n",
      "  Antecedent: frozenset({'B'}), Consequent: frozenset({'C'})\n",
      "  Support(A ∪ B): 0.50, Support(A): 0.67, Confidence: 0.75\n",
      "  Rule passed: frozenset({'B'}) -> frozenset({'C'}), Support: 0.50, Confidence: 0.75\n",
      "  Antecedent: frozenset({'C'}), Consequent: frozenset({'B'})\n",
      "  Support(A ∪ B): 0.50, Support(A): 0.50, Confidence: 1.00\n",
      "  Rule passed: frozenset({'C'}) -> frozenset({'B'}), Support: 0.50, Confidence: 1.00\n",
      "\n",
      "Examining itemset: {'B', 'A'}\n",
      "  Antecedent: frozenset({'B'}), Consequent: frozenset({'A'})\n",
      "  Support(A ∪ B): 0.33, Support(A): 0.67, Confidence: 0.50\n",
      "  Antecedent: frozenset({'A'}), Consequent: frozenset({'B'})\n",
      "  Support(A ∪ B): 0.33, Support(A): 0.67, Confidence: 0.50\n",
      "\n",
      "Examining itemset: {'D', 'E'}\n",
      "  Antecedent: frozenset({'D'}), Consequent: frozenset({'E'})\n",
      "  Support(A ∪ B): 0.17, Support(A): 0.33, Confidence: 0.50\n",
      "  Antecedent: frozenset({'E'}), Consequent: frozenset({'D'})\n",
      "  Support(A ∪ B): 0.17, Support(A): 0.50, Confidence: 0.33\n",
      "\n",
      "Examining itemset: {'D', 'A'}\n",
      "  Antecedent: frozenset({'D'}), Consequent: frozenset({'A'})\n",
      "  Support(A ∪ B): 0.17, Support(A): 0.33, Confidence: 0.50\n",
      "  Antecedent: frozenset({'A'}), Consequent: frozenset({'D'})\n",
      "  Support(A ∪ B): 0.17, Support(A): 0.67, Confidence: 0.25\n",
      "\n",
      "Examining itemset: {'A', 'C'}\n",
      "  Antecedent: frozenset({'A'}), Consequent: frozenset({'C'})\n",
      "  Support(A ∪ B): 0.17, Support(A): 0.67, Confidence: 0.25\n",
      "  Antecedent: frozenset({'C'}), Consequent: frozenset({'A'})\n",
      "  Support(A ∪ B): 0.17, Support(A): 0.50, Confidence: 0.33\n",
      "\n",
      "Examining itemset: {'D', 'C'}\n",
      "  Antecedent: frozenset({'D'}), Consequent: frozenset({'C'})\n",
      "  Support(A ∪ B): 0.17, Support(A): 0.33, Confidence: 0.50\n",
      "  Antecedent: frozenset({'C'}), Consequent: frozenset({'D'})\n",
      "  Support(A ∪ B): 0.17, Support(A): 0.50, Confidence: 0.33\n",
      "\n",
      "Examining itemset: {'B', 'E'}\n",
      "  Antecedent: frozenset({'B'}), Consequent: frozenset({'E'})\n",
      "  Support(A ∪ B): 0.17, Support(A): 0.67, Confidence: 0.25\n",
      "  Antecedent: frozenset({'E'}), Consequent: frozenset({'B'})\n",
      "  Support(A ∪ B): 0.17, Support(A): 0.50, Confidence: 0.33\n",
      "\n",
      "Summary of Association Rules (min support = 0.3333333333333333, min confidence = 0.6):\n",
      "Found 4 rules:\n",
      "Rule: {'A'} -> {'E'}, Support: 0.50, Confidence: 0.75\n",
      "Rule: {'E'} -> {'A'}, Support: 0.50, Confidence: 1.00\n",
      "Rule: {'B'} -> {'C'}, Support: 0.50, Confidence: 0.75\n",
      "Rule: {'C'} -> {'B'}, Support: 0.50, Confidence: 1.00\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def calculate_support(transactions, itemset):\n",
    "    count = sum(1 for transaction in transactions if set(itemset).issubset(transaction))\n",
    "    return count / len(transactions)\n",
    "\n",
    "def generate_frequent_itemsets(transactions, min_support):\n",
    "    itemsets = {}\n",
    "    \n",
    "    # Step 1: Generate single itemsets\n",
    "    for transaction in transactions:\n",
    "        for item in transaction:\n",
    "            if item in itemsets:\n",
    "                itemsets[item] += 1\n",
    "            else:\n",
    "                itemsets[item] = 1\n",
    "\n",
    "    # Step 2: Filter single itemsets based on min_support\n",
    "    frequent_itemsets = {item: count for item, count in itemsets.items() if count >= min_support}\n",
    "    all_frequent_itemsets = [frozenset([item]) for item in frequent_itemsets.keys()]\n",
    "    \n",
    "    print(\"\\nSingle Itemsets and their Support:\")\n",
    "    for item, count in frequent_itemsets.items():\n",
    "        print(f\"Item: {item}, Support: {count / len(transactions):.2f}\")\n",
    "\n",
    "    k = 2  # Start with pairs\n",
    "    while True:\n",
    "        candidates = set()\n",
    "        for combo in combinations(frequent_itemsets.keys(), k):\n",
    "            candidates.add(frozenset(combo))\n",
    "\n",
    "        candidate_counts = {candidate: 0 for candidate in candidates}\n",
    "        for transaction in transactions:\n",
    "            transaction_set = set(transaction)\n",
    "            for candidate in candidates:\n",
    "                if candidate.issubset(transaction_set):\n",
    "                    candidate_counts[candidate] += 1\n",
    "\n",
    "        frequent_candidates = {candidate: count for candidate, count in candidate_counts.items() if count >= min_support}\n",
    "        \n",
    "        if not frequent_candidates:\n",
    "            break\n",
    "\n",
    "        all_frequent_itemsets.extend(frequent_candidates.keys())\n",
    "        frequent_itemsets = {item: count for item, count in frequent_candidates.items()}\n",
    "        k += 1\n",
    "\n",
    "    return all_frequent_itemsets\n",
    "\n",
    "def generate_rules(frequent_itemsets, transactions, min_support, min_confidence):\n",
    "    rules = []\n",
    "    total_transactions = len(transactions)\n",
    "\n",
    "    print(\"\\nGenerating Association Rules:\")\n",
    "    \n",
    "    for itemset in frequent_itemsets:\n",
    "        print(f\"\\nExamining itemset: {set(itemset)}\")\n",
    "        for i in range(1, len(itemset)):\n",
    "            for antecedent in combinations(itemset, i):\n",
    "                antecedent = frozenset(antecedent)\n",
    "                consequent = itemset - antecedent\n",
    "                \n",
    "                if len(consequent) == 0:\n",
    "                    continue\n",
    "                \n",
    "                support_itemset = calculate_support(transactions, itemset)\n",
    "                support_antecedent = calculate_support(transactions, antecedent)\n",
    "                \n",
    "                confidence = support_itemset / support_antecedent if support_antecedent > 0 else 0\n",
    "                \n",
    "                print(f\"  Antecedent: {antecedent}, Consequent: {consequent}\")\n",
    "                print(f\"  Support(A ∪ B): {support_itemset:.2f}, Support(A): {support_antecedent:.2f}, Confidence: {confidence:.2f}\")\n",
    "\n",
    "                if support_itemset >= min_support and confidence >= min_confidence:\n",
    "                    rules.append((antecedent, consequent, support_itemset, confidence))\n",
    "                    print(f\"  Rule passed: {antecedent} -> {consequent}, Support: {support_itemset:.2f}, Confidence: {confidence:.2f}\")\n",
    "\n",
    "    return rules\n",
    "\n",
    "# Example transactions\n",
    "transactions = [\n",
    "    ['A', 'B', 'C'],\n",
    "    ['E', 'D', 'A'],\n",
    "    ['A', 'E'],\n",
    "    ['B', 'C'],\n",
    "    ['A', 'B', 'E'],\n",
    "    ['C', 'B', 'D']\n",
    "]\n",
    "\n",
    "# Minimum support (30% of 6 transactions = 2)\n",
    "min_support = 2 / len(transactions)  # 30%\n",
    "# Minimum confidence\n",
    "min_confidence = 0.6\n",
    "\n",
    "# Step 1: Generate frequent itemsets\n",
    "frequent_itemsets = generate_frequent_itemsets(transactions, min_support)\n",
    "\n",
    "# Step 2: Generate rules\n",
    "rules = generate_rules(frequent_itemsets, transactions, min_support, min_confidence)\n",
    "\n",
    "# Output summary\n",
    "print(\"\\nSummary of Association Rules (min support = {}, min confidence = {}):\".format(min_support, min_confidence))\n",
    "if not rules:\n",
    "    print(\"No rules found that meet the thresholds.\")\n",
    "else:\n",
    "    print(\"Found {} rules:\".format(len(rules)))\n",
    "    for antecedent, consequent, support, confidence in rules:\n",
    "        print(\"Rule: {} -> {}, Support: {:.2f}, Confidence: {:.2f}\".format(\n",
    "            set(antecedent), set(consequent), support, confidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3dec3dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'apply'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     support_consequent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m([t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m transactions \u001b[38;5;28;01mif\u001b[39;00m consequent\u001b[38;5;241m.\u001b[39missubset(t)]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(transactions)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m support_rule \u001b[38;5;241m/\u001b[39m support_consequent\n\u001b[1;32m---> 10\u001b[0m rules[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterest\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mrules\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m(\u001b[38;5;28;01mlambda\u001b[39;00m row: calculate_interest(row, transactions), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInterest Values:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m rules\u001b[38;5;241m.\u001b[39miterrows():\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'apply'"
     ]
    }
   ],
   "source": [
    "# 2c) Interest Calculation\n",
    "# Formula: Given a rule X -> Y, Interest(X -> Y) = Support(X U Y) / Support(Y)\n",
    "def calculate_interest(rule, transactions):\n",
    "    antecedent = set(rule['antecedents'])\n",
    "    consequent = set(rule['consequents'])\n",
    "    support_rule = rule['support']\n",
    "    support_consequent = len([t for t in transactions if consequent.issubset(t)]) / len(transactions)\n",
    "    return support_rule / support_consequent\n",
    "\n",
    "rules['interest'] = rules.apply(lambda row: calculate_interest(row, transactions), axis=1)\n",
    "print(\"\\nInterest Values:\")\n",
    "for index, row in rules.iterrows():\n",
    "    antecedent = ', '.join(row['antecedents'])\n",
    "    consequent = ', '.join(row['consequents'])\n",
    "    interest = row['interest']\n",
    "    print(f\"Rule: {antecedent} -> {consequent}, Interest: {interest:.2f}\")\n",
    "print(\"Formula used for interest: Interest(X -> Y) = Support of (X union Y) / Support of Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d01c0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Single Itemsets and their Support:\n",
      "Item: A, Support: 0.67\n",
      "Item: B, Support: 0.67\n",
      "Item: C, Support: 0.50\n",
      "Item: E, Support: 0.50\n",
      "Item: D, Support: 0.33\n",
      "\n",
      "Generating Association Rules:\n",
      "\n",
      "Examining itemset: {'A'}\n",
      "\n",
      "Examining itemset: {'B'}\n",
      "\n",
      "Examining itemset: {'C'}\n",
      "\n",
      "Examining itemset: {'E'}\n",
      "\n",
      "Examining itemset: {'D'}\n",
      "\n",
      "Examining itemset: {'D', 'B'}\n",
      "  Antecedent: frozenset({'D'}), Consequent: frozenset({'B'})\n",
      "  Support(A ∪ B): 0.17, Support(A): 0.33, Confidence: 0.50\n",
      "  Antecedent: frozenset({'B'}), Consequent: frozenset({'D'})\n",
      "  Support(A ∪ B): 0.17, Support(A): 0.67, Confidence: 0.25\n",
      "\n",
      "Examining itemset: {'A', 'E'}\n",
      "  Antecedent: frozenset({'A'}), Consequent: frozenset({'E'})\n",
      "  Support(A ∪ B): 0.50, Support(A): 0.67, Confidence: 0.75\n",
      "  Rule passed: frozenset({'A'}) -> frozenset({'E'}), Support: 0.50, Confidence: 0.75\n",
      "  Antecedent: frozenset({'E'}), Consequent: frozenset({'A'})\n",
      "  Support(A ∪ B): 0.50, Support(A): 0.50, Confidence: 1.00\n",
      "  Rule passed: frozenset({'E'}) -> frozenset({'A'}), Support: 0.50, Confidence: 1.00\n",
      "\n",
      "Examining itemset: {'B', 'C'}\n",
      "  Antecedent: frozenset({'B'}), Consequent: frozenset({'C'})\n",
      "  Support(A ∪ B): 0.50, Support(A): 0.67, Confidence: 0.75\n",
      "  Rule passed: frozenset({'B'}) -> frozenset({'C'}), Support: 0.50, Confidence: 0.75\n",
      "  Antecedent: frozenset({'C'}), Consequent: frozenset({'B'})\n",
      "  Support(A ∪ B): 0.50, Support(A): 0.50, Confidence: 1.00\n",
      "  Rule passed: frozenset({'C'}) -> frozenset({'B'}), Support: 0.50, Confidence: 1.00\n",
      "\n",
      "Examining itemset: {'B', 'A'}\n",
      "  Antecedent: frozenset({'B'}), Consequent: frozenset({'A'})\n",
      "  Support(A ∪ B): 0.33, Support(A): 0.67, Confidence: 0.50\n",
      "  Antecedent: frozenset({'A'}), Consequent: frozenset({'B'})\n",
      "  Support(A ∪ B): 0.33, Support(A): 0.67, Confidence: 0.50\n",
      "\n",
      "Examining itemset: {'D', 'E'}\n",
      "  Antecedent: frozenset({'D'}), Consequent: frozenset({'E'})\n",
      "  Support(A ∪ B): 0.17, Support(A): 0.33, Confidence: 0.50\n",
      "  Antecedent: frozenset({'E'}), Consequent: frozenset({'D'})\n",
      "  Support(A ∪ B): 0.17, Support(A): 0.50, Confidence: 0.33\n",
      "\n",
      "Examining itemset: {'D', 'A'}\n",
      "  Antecedent: frozenset({'D'}), Consequent: frozenset({'A'})\n",
      "  Support(A ∪ B): 0.17, Support(A): 0.33, Confidence: 0.50\n",
      "  Antecedent: frozenset({'A'}), Consequent: frozenset({'D'})\n",
      "  Support(A ∪ B): 0.17, Support(A): 0.67, Confidence: 0.25\n",
      "\n",
      "Examining itemset: {'A', 'C'}\n",
      "  Antecedent: frozenset({'A'}), Consequent: frozenset({'C'})\n",
      "  Support(A ∪ B): 0.17, Support(A): 0.67, Confidence: 0.25\n",
      "  Antecedent: frozenset({'C'}), Consequent: frozenset({'A'})\n",
      "  Support(A ∪ B): 0.17, Support(A): 0.50, Confidence: 0.33\n",
      "\n",
      "Examining itemset: {'D', 'C'}\n",
      "  Antecedent: frozenset({'D'}), Consequent: frozenset({'C'})\n",
      "  Support(A ∪ B): 0.17, Support(A): 0.33, Confidence: 0.50\n",
      "  Antecedent: frozenset({'C'}), Consequent: frozenset({'D'})\n",
      "  Support(A ∪ B): 0.17, Support(A): 0.50, Confidence: 0.33\n",
      "\n",
      "Examining itemset: {'B', 'E'}\n",
      "  Antecedent: frozenset({'B'}), Consequent: frozenset({'E'})\n",
      "  Support(A ∪ B): 0.17, Support(A): 0.67, Confidence: 0.25\n",
      "  Antecedent: frozenset({'E'}), Consequent: frozenset({'B'})\n",
      "  Support(A ∪ B): 0.17, Support(A): 0.50, Confidence: 0.33\n",
      "\n",
      "Step 3: Calculate Interest for Each Rule\n",
      "Rule: frozenset({'A'}) -> frozenset({'E'}), Interest: 0.17\n",
      "Rule: frozenset({'E'}) -> frozenset({'A'}), Interest: 0.17\n",
      "Rule: frozenset({'B'}) -> frozenset({'C'}), Interest: 0.17\n",
      "Rule: frozenset({'C'}) -> frozenset({'B'}), Interest: 0.17\n",
      "\n",
      "Final Interests of the Rules:\n",
      "Rule: frozenset({'A'}) -> frozenset({'E'}), Interest: 0.17\n",
      "Rule: frozenset({'E'}) -> frozenset({'A'}), Interest: 0.17\n",
      "Rule: frozenset({'B'}) -> frozenset({'C'}), Interest: 0.17\n",
      "Rule: frozenset({'C'}) -> frozenset({'B'}), Interest: 0.17\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def calculate_support(transactions, itemset):\n",
    "    count = sum(1 for transaction in transactions if set(itemset).issubset(transaction))\n",
    "    return count / len(transactions)\n",
    "\n",
    "def generate_frequent_itemsets(transactions, min_support):\n",
    "    itemsets = {}\n",
    "    \n",
    "    # Step 1: Generate single itemsets\n",
    "    for transaction in transactions:\n",
    "        for item in transaction:\n",
    "            if item in itemsets:\n",
    "                itemsets[item] += 1\n",
    "            else:\n",
    "                itemsets[item] = 1\n",
    "\n",
    "    # Step 2: Filter single itemsets based on min_support\n",
    "    frequent_itemsets = {item: count for item, count in itemsets.items() if count >= min_support}\n",
    "    all_frequent_itemsets = [frozenset([item]) for item in frequent_itemsets.keys()]\n",
    "    \n",
    "    print(\"\\nSingle Itemsets and their Support:\")\n",
    "    for item, count in frequent_itemsets.items():\n",
    "        print(f\"Item: {item}, Support: {count / len(transactions):.2f}\")\n",
    "\n",
    "    k = 2  # Start with pairs\n",
    "    while True:\n",
    "        candidates = set()\n",
    "        for combo in combinations(frequent_itemsets.keys(), k):\n",
    "            candidates.add(frozenset(combo))\n",
    "\n",
    "        candidate_counts = {candidate: 0 for candidate in candidates}\n",
    "        for transaction in transactions:\n",
    "            transaction_set = set(transaction)\n",
    "            for candidate in candidates:\n",
    "                if candidate.issubset(transaction_set):\n",
    "                    candidate_counts[candidate] += 1\n",
    "\n",
    "        frequent_candidates = {candidate: count for candidate, count in candidate_counts.items() if count >= min_support}\n",
    "        \n",
    "        if not frequent_candidates:\n",
    "            break\n",
    "\n",
    "        all_frequent_itemsets.extend(frequent_candidates.keys())\n",
    "        frequent_itemsets = {item: count for item, count in frequent_candidates.items()}\n",
    "        k += 1\n",
    "\n",
    "    return all_frequent_itemsets\n",
    "\n",
    "def generate_rules(frequent_itemsets, transactions, min_support, min_confidence):\n",
    "    rules = []\n",
    "    total_transactions = len(transactions)\n",
    "\n",
    "    print(\"\\nGenerating Association Rules:\")\n",
    "    \n",
    "    for itemset in frequent_itemsets:\n",
    "        print(f\"\\nExamining itemset: {set(itemset)}\")\n",
    "        for i in range(1, len(itemset)):\n",
    "            for antecedent in combinations(itemset, i):\n",
    "                antecedent = frozenset(antecedent)\n",
    "                consequent = itemset - antecedent\n",
    "                \n",
    "                if len(consequent) == 0:\n",
    "                    continue\n",
    "                \n",
    "                support_itemset = calculate_support(transactions, itemset)\n",
    "                support_antecedent = calculate_support(transactions, antecedent)\n",
    "                \n",
    "                confidence = support_itemset / support_antecedent if support_antecedent > 0 else 0\n",
    "                \n",
    "                print(f\"  Antecedent: {antecedent}, Consequent: {consequent}\")\n",
    "                print(f\"  Support(A ∪ B): {support_itemset:.2f}, Support(A): {support_antecedent:.2f}, Confidence: {confidence:.2f}\")\n",
    "\n",
    "                if support_itemset >= min_support and confidence >= min_confidence:\n",
    "                    rules.append((antecedent, consequent, support_itemset, confidence))\n",
    "                    print(f\"  Rule passed: {antecedent} -> {consequent}, Support: {support_itemset:.2f}, Confidence: {confidence:.2f}\")\n",
    "\n",
    "    return rules\n",
    "\n",
    "def calculate_interest(rules, transactions):\n",
    "    print(\"\\nStep 3: Calculate Interest for Each Rule\")\n",
    "    interests = []\n",
    "    for antecedent, consequent, support_itemset, confidence in rules:\n",
    "        support_antecedent = calculate_support(transactions, antecedent)\n",
    "        support_consequent = calculate_support(transactions, consequent)\n",
    "        \n",
    "        # Calculate expected support\n",
    "        expected_support = support_antecedent * support_consequent\n",
    "        interest = support_itemset - expected_support\n",
    "        \n",
    "        interests.append((antecedent, consequent, interest))\n",
    "        print(f\"Rule: {antecedent} -> {consequent}, Interest: {interest:.2f}\")\n",
    "\n",
    "    return interests\n",
    "\n",
    "# Example transactions\n",
    "transactions = [\n",
    "    ['A', 'B', 'C'],\n",
    "    ['E', 'D', 'A'],\n",
    "    ['A', 'E'],\n",
    "    ['B', 'C'],\n",
    "    ['A', 'B', 'E'],\n",
    "    ['C', 'B', 'D']\n",
    "]\n",
    "\n",
    "# Minimum support (30% of 6 transactions = 2)\n",
    "min_support = 2 / len(transactions)  # 30%\n",
    "# Minimum confidence\n",
    "min_confidence = 0.6\n",
    "\n",
    "# Step 1: Generate frequent itemsets\n",
    "frequent_itemsets = generate_frequent_itemsets(transactions, min_support)\n",
    "\n",
    "# Step 2: Generate rules\n",
    "rules = generate_rules(frequent_itemsets, transactions, min_support, min_confidence)\n",
    "\n",
    "# Step 3: Calculate interest for the generated rules\n",
    "interests = calculate_interest(rules, transactions)\n",
    "\n",
    "# Final Output of Interests\n",
    "print(\"\\nFinal Interests of the Rules:\")\n",
    "if not interests:\n",
    "    print(\"No interests calculated for the rules.\")\n",
    "else:\n",
    "    for antecedent, consequent, interest in interests:\n",
    "        print(f\"Rule: {antecedent} -> {consequent}, Interest: {interest:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7862a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 1 Shingles:\n",
      "Shingle: the cat sits\n",
      "Shingle: cat sits on\n",
      "Shingle: sits on the\n",
      "Shingle: on the mat\n",
      "Shingle: the mat and\n",
      "Shingle: mat and looks\n",
      "Shingle: and looks very\n",
      "Shingle: looks very calm\n",
      "\n",
      "Document 2 Shingles:\n",
      "Shingle: the cat sits\n",
      "Shingle: cat sits calmly\n",
      "Shingle: sits calmly on\n",
      "Shingle: calmly on the\n",
      "Shingle: on the mat\n",
      "Shingle: the mat while\n",
      "Shingle: mat while the\n",
      "Shingle: while the dog\n",
      "Shingle: the dog plays\n",
      "Shingle: dog plays nearby\n",
      "\n",
      "Document 3 Shingles:\n",
      "Shingle: on the grass\n",
      "Shingle: the grass the\n",
      "Shingle: grass the dog\n",
      "Shingle: the dog plays\n",
      "Shingle: dog plays joyfully\n",
      "Shingle: plays joyfully as\n",
      "Shingle: joyfully as the\n",
      "Shingle: as the cat\n",
      "Shingle: the cat watches\n",
      "Shingle: cat watches quietly\n",
      "A shingle is a contiguous subsequence of length n in a document.\n",
      "\n",
      "Jaccard Similarities:\n",
      "      Doc1  Doc2  Doc3\n",
      "Doc1  0.00  0.12  0.00\n",
      "Doc2  0.12  0.00  0.05\n",
      "Doc3  0.00  0.05  0.00\n",
      "Formula used for Jaccard similarity: J(A, B) = (Size of the intersection of A and B) / (Size of the union of A and B)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 70\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m7\u001b[39m):\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m input_matrix[row, col] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 70\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mperm\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m<\u001b[39m min_hash:\n\u001b[0;32m     71\u001b[0m             min_hash \u001b[38;5;241m=\u001b[39m perm[row]\n\u001b[0;32m     72\u001b[0m signature[i, col] \u001b[38;5;241m=\u001b[39m min_hash\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Question 3\n",
    "def get_shingles(text, n=3):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "    words = text.split()\n",
    "    return [tuple(words[i:i + n]) for i in range(len(words) - n + 1)]\n",
    "\n",
    "docs = [\n",
    "    \"The cat sits on the mat and looks very calm\",\n",
    "    \"The cat sits calmly on the mat while the dog plays nearby\",\n",
    "    \"On the grass the dog plays joyfully as the cat watches quietly\"\n",
    "]\n",
    "# 3a) 3 - Shingles\n",
    "# Shingles are contiguous subsequences of length n in a document\n",
    "for i, doc in enumerate(docs, 1):\n",
    "    shingles = get_shingles(doc)\n",
    "    print(f\"\\nDocument {i} Shingles:\")\n",
    "    for shingle in shingles:\n",
    "        print(f\"Shingle: {' '.join(shingle)}\")\n",
    "print(\"A shingle is a contiguous subsequence of length n in a document.\")\n",
    "\n",
    "# 3b) Jaccard Similarity\n",
    "# Formula: Given two sets A and B, J(A, B) = (Size of (A intersection B)) / (Size of (A union B))\n",
    "all_shingles = set()\n",
    "for doc in docs:\n",
    "    all_shingles.update(get_shingles(doc))\n",
    "all_shingles = list(all_shingles)\n",
    "matrix = []\n",
    "for doc in docs:\n",
    "    shingles = set(get_shingles(doc))\n",
    "    row = [1 if s in shingles else 0 for s in all_shingles]\n",
    "    matrix.append(row)\n",
    "similarities = []\n",
    "for i in range(3):\n",
    "    for j in range(i + 1, 3):\n",
    "        sim = jaccard_score(matrix[i], matrix[j])\n",
    "        similarities.append((i + 1, j + 1, sim))\n",
    "print(\"\\nJaccard Similarities:\")\n",
    "sim_matrix = np.zeros((3, 3))\n",
    "for i, j, sim in similarities:\n",
    "    sim_matrix[i - 1, j - 1] = sim\n",
    "    sim_matrix[j - 1, i - 1] = sim\n",
    "df_sim = pd.DataFrame(sim_matrix, columns=['Doc1', 'Doc2', 'Doc3'], index=['Doc1', 'Doc2', 'Doc3'])\n",
    "print(df_sim.round(2))\n",
    "print(\"Formula used for Jaccard similarity: J(A, B) = (Size of the intersection of A and B) / (Size of the union of A and B)\")\n",
    "\n",
    "# 3c) Minhashing\n",
    "# Min - hash value of a column C for a permutation pi is the minimum value of pi(r) for all r in C where r = 1\n",
    "input_matrix = np.array([\n",
    "    [1, 0, 1, 0],\n",
    "    [0, 0, 1, 1],\n",
    "    [1, 1, 0, 1],\n",
    "    [0, 1, 0, 0],\n",
    "    [0, 0, 1, 1],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 1, 0, 1]\n",
    "])\n",
    "permutations = [\n",
    "    [4, 3, 5, 2],\n",
    "    [2, 7, 1, 5],\n",
    "    [6, 1, 4, 3],\n",
    "    [1, 5, 6, 7]\n",
    "]\n",
    "signature = np.zeros((4, 4), dtype=int)\n",
    "for i in range(4):\n",
    "    perm = permutations[i]\n",
    "    for col in range(4):\n",
    "        min_hash = np.inf\n",
    "        for row in range(7):\n",
    "            if input_matrix[row, col] == 1:\n",
    "                if perm[row] < min_hash:\n",
    "                    min_hash = perm[row]\n",
    "        signature[i, col] = min_hash\n",
    "print(\"\\nSignature Matrix:\")\n",
    "df_signature = pd.DataFrame(signature, columns=['Col1', 'Col2', 'Col3', 'Col4'], index=['Row1', 'Row2', 'Row3', 'Row4'])\n",
    "print(df_signature)\n",
    "print(\"Formula used for min - hashing: Min - hash value of a column C for a permutation pi = minimum of pi(r) for all r in C where r = 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4108479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Document 1...\n",
      "Normalized Text: 'the cat sits on the mat and looks very calm'\n",
      "3-Shingles: {'mat and looks', 'on the mat', 'the mat and', 'and looks very', 'sits on the', 'the cat sits', 'looks very calm', 'cat sits on'}\n",
      "\n",
      "Processing Document 2...\n",
      "Normalized Text: 'the cat sits calmly on the mat while the dog plays nearby'\n",
      "3-Shingles: {'dog plays nearby', 'on the mat', 'sits calmly on', 'the dog plays', 'calmly on the', 'the cat sits', 'while the dog', 'mat while the', 'cat sits calmly', 'the mat while'}\n",
      "\n",
      "Processing Document 3...\n",
      "Normalized Text: 'on the grass the dog plays joyfully as the cat watches quietly'\n",
      "3-Shingles: {'the cat watches', 'the grass the', 'on the grass', 'cat watches quietly', 'plays joyfully as', 'dog plays joyfully', 'grass the dog', 'as the cat', 'joyfully as the', 'the dog plays'}\n",
      "\n",
      "Final 3-Shingle Results:\n",
      "Document 1: {'mat and looks', 'on the mat', 'the mat and', 'and looks very', 'sits on the', 'the cat sits', 'looks very calm', 'cat sits on'}\n",
      "Document 2: {'dog plays nearby', 'on the mat', 'sits calmly on', 'the dog plays', 'calmly on the', 'the cat sits', 'while the dog', 'mat while the', 'cat sits calmly', 'the mat while'}\n",
      "Document 3: {'the cat watches', 'the grass the', 'on the grass', 'cat watches quietly', 'plays joyfully as', 'dog plays joyfully', 'grass the dog', 'as the cat', 'joyfully as the', 'the dog plays'}\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "# Function to normalize text by removing punctuation and converting to lowercase\n",
    "def normalize_text(text):\n",
    "    # Remove punctuation and convert to lowercase\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    normalized_text = text.translate(translator).lower()\n",
    "    return normalized_text\n",
    "\n",
    "# Function to generate 3-shingles (three consecutive words) from normalized text\n",
    "def generate_shingles(text, k=3):\n",
    "    words = text.split()\n",
    "    shingles = set()\n",
    "    for i in range(len(words) - k + 1):\n",
    "        shingle = ' '.join(words[i:i + k])\n",
    "        shingles.add(shingle)\n",
    "    return shingles\n",
    "\n",
    "# Documents\n",
    "documents = {\n",
    "    \"Document 1\": \"The cat sits on the mat and looks very calm.\",\n",
    "    \"Document 2\": \"The cat sits calmly on the mat, while the dog plays nearby.\",\n",
    "    \"Document 3\": \"On the grass, the dog plays joyfully as the cat watches quietly.\"\n",
    "}\n",
    "\n",
    "# Process each document\n",
    "shingle_results = {}\n",
    "for doc_name, content in documents.items():\n",
    "    print(f\"Processing {doc_name}...\")\n",
    "    \n",
    "    # Step 1: Normalize the text\n",
    "    normalized_content = normalize_text(content)\n",
    "    print(f\"Normalized Text: '{normalized_content}'\")\n",
    "    \n",
    "    # Step 2: Generate 3-shingles\n",
    "    shingles = generate_shingles(normalized_content, k=3)\n",
    "    shingle_results[doc_name] = shingles\n",
    "    \n",
    "    # Step 3: Print the shingles\n",
    "    print(f\"3-Shingles: {shingles}\\n\")\n",
    "\n",
    "# Final results\n",
    "print(\"Final 3-Shingle Results:\")\n",
    "for doc_name, shingles in shingle_results.items():\n",
    "    print(f\"{doc_name}: {shingles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6eb7662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Shingles Across All Documents:\n",
      "{'cat watches quietly', 'on the mat', 'the mat and', 'and looks very', 'sits on the', 'dog plays joyfully', 'calmly on the', 'looks very calm', 'grass the dog', 'joyfully as the', 'cat sits on', 'mat while the', 'the dog plays', 'the mat while', 'dog plays nearby', 'mat and looks', 'the cat watches', 'the grass the', 'on the grass', 'sits calmly on', 'the cat sits', 'as the cat', 'while the dog', 'cat sits calmly', 'plays joyfully as'}\n",
      "\n",
      "Shingle Matrix (Rows: Shingles, Columns: Documents):\n",
      "cat watches quietly: [0, 0, 1]\n",
      "on the mat: [1, 1, 0]\n",
      "the mat and: [1, 0, 0]\n",
      "and looks very: [1, 0, 0]\n",
      "sits on the: [1, 0, 0]\n",
      "dog plays joyfully: [0, 0, 1]\n",
      "calmly on the: [0, 1, 0]\n",
      "looks very calm: [1, 0, 0]\n",
      "grass the dog: [0, 0, 1]\n",
      "joyfully as the: [0, 0, 1]\n",
      "cat sits on: [1, 0, 0]\n",
      "mat while the: [0, 1, 0]\n",
      "the dog plays: [0, 1, 1]\n",
      "the mat while: [0, 1, 0]\n",
      "dog plays nearby: [0, 1, 0]\n",
      "mat and looks: [1, 0, 0]\n",
      "the cat watches: [0, 0, 1]\n",
      "the grass the: [0, 0, 1]\n",
      "on the grass: [0, 0, 1]\n",
      "sits calmly on: [0, 1, 0]\n",
      "the cat sits: [1, 1, 0]\n",
      "as the cat: [0, 0, 1]\n",
      "while the dog: [0, 1, 0]\n",
      "cat sits calmly: [0, 1, 0]\n",
      "plays joyfully as: [0, 0, 1]\n",
      "\n",
      "Jaccard Similarity Matrix:\n",
      "Similarity between Document 1 and Document 2: 0.1250\n",
      "Similarity between Document 1 and Document 3: 0.0000\n",
      "Similarity between Document 2 and Document 3: 0.0526\n",
      "\n",
      "Final Jaccard Similarity Matrix:\n",
      "[0, 0.125, 0.0]\n",
      "[0.125, 0, 0.05263157894736842]\n",
      "[0.0, 0.05263157894736842, 0]\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "# Function to normalize text by removing punctuation and converting to lowercase\n",
    "def normalize_text(text):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    normalized_text = text.translate(translator).lower()\n",
    "    return normalized_text\n",
    "\n",
    "# Function to generate 3-shingles (three consecutive words) from normalized text\n",
    "def generate_shingles(text, k=3):\n",
    "    words = text.split()\n",
    "    shingles = set()\n",
    "    for i in range(len(words) - k + 1):\n",
    "        shingle = ' '.join(words[i:i + k])\n",
    "        shingles.add(shingle)\n",
    "    return shingles\n",
    "\n",
    "# Function to calculate Jaccard similarity\n",
    "def jaccard_similarity(set1, set2):\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union != 0 else 0\n",
    "\n",
    "# Documents\n",
    "documents = {\n",
    "    \"Document 1\": \"The cat sits on the mat and looks very calm.\",\n",
    "    \"Document 2\": \"The cat sits calmly on the mat, while the dog plays nearby.\",\n",
    "    \"Document 3\": \"On the grass, the dog plays joyfully as the cat watches quietly.\"\n",
    "}\n",
    "\n",
    "# Step 1: Generate 3-shingles for each document\n",
    "shingle_results = {}\n",
    "for doc_name, content in documents.items():\n",
    "    normalized_content = normalize_text(content)\n",
    "    shingles = generate_shingles(normalized_content, k=3)\n",
    "    shingle_results[doc_name] = shingles\n",
    "\n",
    "# Step 2: Create a set of all unique shingles\n",
    "all_shingles = set()\n",
    "for shingles in shingle_results.values():\n",
    "    all_shingles.update(shingles)\n",
    "\n",
    "print(\"Unique Shingles Across All Documents:\")\n",
    "print(all_shingles)\n",
    "\n",
    "# Step 3: Construct the shingle matrix\n",
    "shingle_matrix = {shingle: [0] * len(documents) for shingle in all_shingles}\n",
    "doc_index = {doc_name: idx for idx, doc_name in enumerate(documents.keys())}\n",
    "\n",
    "for doc_name, shingles in shingle_results.items():\n",
    "    for shingle in shingles:\n",
    "        shingle_matrix[shingle][doc_index[doc_name]] = 1\n",
    "\n",
    "# Display the shingle matrix\n",
    "print(\"\\nShingle Matrix (Rows: Shingles, Columns: Documents):\")\n",
    "for shingle, row in shingle_matrix.items():\n",
    "    print(f\"{shingle}: {row}\")\n",
    "\n",
    "# Step 4: Calculate Jaccard similarity for each pair of documents\n",
    "doc_names = list(documents.keys())\n",
    "num_docs = len(doc_names)\n",
    "jaccard_matrix = [[0] * num_docs for _ in range(num_docs)]\n",
    "\n",
    "print(\"\\nJaccard Similarity Matrix:\")\n",
    "for i in range(num_docs):\n",
    "    for j in range(i + 1, num_docs):\n",
    "        sim = jaccard_similarity(shingle_results[doc_names[i]], shingle_results[doc_names[j]])\n",
    "        jaccard_matrix[i][j] = sim\n",
    "        jaccard_matrix[j][i] = sim  # Symmetric matrix\n",
    "        print(f\"Similarity between {doc_names[i]} and {doc_names[j]}: {sim:.4f}\")\n",
    "\n",
    "# Display the final Jaccard similarity matrix\n",
    "print(\"\\nFinal Jaccard Similarity Matrix:\")\n",
    "for row in jaccard_matrix:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d0152d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-Shingle Matrix M:\n",
      "Rows (Shingles): ['and looks very', 'as the cat', 'calmly on the', 'cat sits calmly', 'cat sits on', 'cat watches quietly', 'dog plays joyfully', 'dog plays nearby', 'grass the dog', 'joyfully as the', 'looks very calm', 'mat and looks', 'mat while the', 'on the grass', 'on the mat', 'plays joyfully as', 'sits calmly on', 'sits on the', 'the cat sits', 'the cat watches', 'the dog plays', 'the grass the', 'the mat and', 'the mat while', 'while the dog']\n",
      "Matrix:\n",
      " [[1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 1 0]\n",
      " [0 0 1]\n",
      " [0 1 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]]\n",
      "\n",
      "Jaccard Similarities:\n",
      "Doc1 & Doc2: 0.125\n",
      "Doc1 & Doc3: 0.000\n",
      "Doc2 & Doc3: 0.053\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 各文档的shingles（假设已生成）\n",
    "doc1_shingles = {'the cat sits', 'cat sits on', 'sits on the', 'on the mat', 'the mat and', 'mat and looks', 'and looks very', 'looks very calm'}\n",
    "doc2_shingles = {'the cat sits', 'cat sits calmly', 'sits calmly on', 'calmly on the', 'on the mat', 'the mat while', 'mat while the', 'while the dog', 'the dog plays', 'dog plays nearby'}\n",
    "doc3_shingles = {'on the grass', 'the grass the', 'grass the dog', 'the dog plays', 'dog plays joyfully', 'plays joyfully as', 'joyfully as the', 'as the cat', 'the cat watches', 'cat watches quietly'}\n",
    "\n",
    "# 合并所有唯一shingles并排序\n",
    "all_shingles = sorted(doc1_shingles | doc2_shingles | doc3_shingles)\n",
    "\n",
    "# 初始化矩阵M（行：shingles，列：文档）\n",
    "M = np.zeros((len(all_shingles), 3), dtype=int)\n",
    "\n",
    "# 填充矩阵\n",
    "for i, shingle in enumerate(all_shingles):\n",
    "    M[i][0] = 1 if shingle in doc1_shingles else 0\n",
    "    M[i][1] = 1 if shingle in doc2_shingles else 0\n",
    "    M[i][2] = 1 if shingle in doc3_shingles else 0\n",
    "\n",
    "# 打印矩阵\n",
    "print(\"3-Shingle Matrix M:\")\n",
    "print(\"Rows (Shingles):\", all_shingles)\n",
    "print(\"Matrix:\\n\", M)\n",
    "def jaccard_similarity(col1, col2):\n",
    "    intersection = np.dot(col1, col2)\n",
    "    union = np.sum(col1) + np.sum(col2) - intersection\n",
    "    return intersection / union if union != 0 else 0\n",
    "\n",
    "# 计算所有文档对的相似度\n",
    "pairs = [(0, 1), (0, 2), (1, 2)]\n",
    "results = {}\n",
    "for pair in pairs:\n",
    "    doc_a, doc_b = pair\n",
    "    sim = jaccard_similarity(M[:, doc_a], M[:, doc_b])\n",
    "    results[f\"Doc{doc_a+1} & Doc{doc_b+1}\"] = sim\n",
    "\n",
    "# 打印结果\n",
    "print(\"\\nJaccard Similarities:\")\n",
    "for pair, sim in results.items():\n",
    "    print(f\"{pair}: {sim:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1945f263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Similarities:\n",
      "Doc 1 vs Doc 2: 0.12\n",
      "Doc 1 vs Doc 3: 0.00\n",
      "Doc 2 vs Doc 3: 0.05\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 79\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m7\u001b[39m):\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m input_matrix[row, col] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mperm\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m<\u001b[39m min_hash:\n\u001b[0;32m     80\u001b[0m             min_hash \u001b[38;5;241m=\u001b[39m perm[row]\n\u001b[0;32m     81\u001b[0m signature[i, col] \u001b[38;5;241m=\u001b[39m min_hash\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define the get_shingles function\n",
    "def get_shingles(text, n=3):\n",
    "    text = text.lower().replace(\",\", \"\").replace(\".\", \"\")\n",
    "    words = text.split()\n",
    "    return [tuple(words[i:i + n]) for i in range(len(words) - n + 1)]\n",
    "\n",
    "\n",
    "# Define docs\n",
    "docs = [\n",
    "    \"The cat sits on the mat and looks very calm\",\n",
    "    \"The cat sits calmly on the mat while the dog plays nearby\",\n",
    "    \"On the grass the dog plays joyfully as the cat watches quietly\"\n",
    "]\n",
    "\n",
    "# Calculate Jaccard similarities\n",
    "all_shingles = set()\n",
    "for doc in docs:\n",
    "    all_shingles.update(get_shingles(doc))\n",
    "all_shingles = list(all_shingles)\n",
    "\n",
    "matrix = []\n",
    "for doc in docs:\n",
    "    shingles = set(get_shingles(doc))\n",
    "    row = [1 if s in shingles else 0 for s in all_shingles]\n",
    "    matrix.append(row)\n",
    "\n",
    "\n",
    "def custom_jaccard_score(set1, set2):\n",
    "    intersection = sum([1 for i in range(len(set1)) if set1[i] == 1 and set2[i] == 1])\n",
    "    union = sum([1 for i in range(len(set1)) if set1[i] == 1 or set2[i] == 1])\n",
    "    if union == 0:\n",
    "        return 0\n",
    "    return intersection / union\n",
    "\n",
    "\n",
    "similarities = []\n",
    "for i in range(3):\n",
    "    for j in range(i + 1, 3):\n",
    "        sim = custom_jaccard_score(matrix[i], matrix[j])\n",
    "        similarities.append((i + 1, j + 1, sim))\n",
    "\n",
    "print(\"\\nJaccard Similarities:\")\n",
    "for pair in similarities:\n",
    "    print(f\"Doc {pair[0]} vs Doc {pair[1]}: {pair[2]:.2f}\")\n",
    "\n",
    "# Input matrix\n",
    "input_matrix = np.array([\n",
    "    [1, 0, 1, 0],\n",
    "    [0, 0, 1, 1],\n",
    "    [1, 1, 0, 1],\n",
    "    [0, 1, 0, 0],\n",
    "    [1, 0, 1, 1],\n",
    "    [1, 0, 0, 0],\n",
    "    [0, 1, 0, 1]\n",
    "])\n",
    "\n",
    "# Random permutations\n",
    "permutations = [\n",
    "    [4, 3, 5, 2],\n",
    "    [2, 7, 1, 5],\n",
    "    [6, 1, 4, 3],\n",
    "    [1, 5, 6, 7],\n",
    "    [5, 2, 2, 1],\n",
    "    [3, 6, 7, 4],\n",
    "    [7, 4, 3, 6]\n",
    "]\n",
    "\n",
    "# Compute signature matrix\n",
    "signature = np.zeros((4, 4), dtype=int)\n",
    "for i in range(4):\n",
    "    perm = permutations[i]\n",
    "    for col in range(4):\n",
    "        min_hash = np.inf\n",
    "        for row in range(7):\n",
    "            if input_matrix[row, col] == 1:\n",
    "                if perm[row] < min_hash:\n",
    "                    min_hash = perm[row]\n",
    "        signature[i, col] = min_hash\n",
    "\n",
    "print(\"\\nSignature Matrix:\")\n",
    "print(signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b09707ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Similarity Matrix for Input Matrix:\n",
      "[[0.         0.33333333 0.25       0.         0.66666667 0.5\n",
      "  0.        ]\n",
      " [0.33333333 0.         0.25       0.         0.66666667 0.\n",
      "  0.33333333]\n",
      " [0.25       0.25       0.         0.33333333 0.5        0.33333333\n",
      "  0.66666667]\n",
      " [0.         0.         0.33333333 0.         0.         0.\n",
      "  0.5       ]\n",
      " [0.66666667 0.66666667 0.5        0.         0.         0.33333333\n",
      "  0.25      ]\n",
      " [0.5        0.         0.33333333 0.         0.33333333 0.\n",
      "  0.        ]\n",
      " [0.         0.33333333 0.66666667 0.5        0.25       0.\n",
      "  0.        ]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 1 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 63\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m signature_matrix\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Generate the signature matrix\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m signature_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mminhashing\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpermutations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSignature Matrix from Minhashing:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(signature_matrix)\n",
      "Cell \u001b[1;32mIn[40], line 56\u001b[0m, in \u001b[0;36mminhashing\u001b[1;34m(matrix, permutations)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_items):\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature_index \u001b[38;5;129;01min\u001b[39;00m perm:  \u001b[38;5;66;03m# Use the permutation directly\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mmatrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# Adjust for 0-based indexing\u001b[39;00m\n\u001b[0;32m     57\u001b[0m             signature_matrix[perm_index, item_index] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(signature_matrix[perm_index, item_index], feature_index)\n\u001b[0;32m     58\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Stop after the first 1 is found\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 4 is out of bounds for axis 1 with size 4"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Step 1: Define the input matrix\n",
    "input_matrix = np.array([\n",
    "    [1, 0, 1, 0],\n",
    "    [0, 0, 1, 1],\n",
    "    [1, 1, 0, 1],\n",
    "    [0, 1, 0, 0],\n",
    "    [1, 0, 1, 1],\n",
    "    [1, 0, 0, 0],\n",
    "    [0, 1, 0, 1]\n",
    "])\n",
    "\n",
    "# Step 2: Random permutations provided\n",
    "permutations = [\n",
    "    [4, 3, 5, 2],\n",
    "    [2, 7, 1, 5],\n",
    "    [6, 1, 4, 3],\n",
    "    [1, 5, 6, 7],\n",
    "    [5, 2, 2, 1],\n",
    "    [3, 6, 7, 4],\n",
    "    [7, 4, 3, 6]\n",
    "]\n",
    "\n",
    "# Step 3: Calculate Jaccard similarity for the input matrix\n",
    "def jaccard_similarity(matrix):\n",
    "    num_items = matrix.shape[0]\n",
    "    similarity_matrix = np.zeros((num_items, num_items))\n",
    "    \n",
    "    for i in range(num_items):\n",
    "        for j in range(i + 1, num_items):\n",
    "            # Calculate intersection and union\n",
    "            intersection = np.sum(np.logical_and(matrix[i], matrix[j]))\n",
    "            union = np.sum(np.logical_or(matrix[i], matrix[j]))\n",
    "            similarity = intersection / union if union > 0 else 0\n",
    "            similarity_matrix[i, j] = similarity\n",
    "            similarity_matrix[j, i] = similarity  # Symmetric\n",
    "            \n",
    "    return similarity_matrix\n",
    "\n",
    "# Calculate Jaccard similarity for the input matrix\n",
    "input_jaccard_matrix = jaccard_similarity(input_matrix)\n",
    "print(\"Jaccard Similarity Matrix for Input Matrix:\")\n",
    "print(input_jaccard_matrix)\n",
    "\n",
    "# Step 4: Apply Minhashing using the provided permutations\n",
    "def minhashing(matrix, permutations):\n",
    "    num_items = matrix.shape[0]\n",
    "    num_permutations = len(permutations)\n",
    "    signature_matrix = np.full((num_permutations, num_items), np.inf)\n",
    "    \n",
    "    for perm_index in range(num_permutations):\n",
    "        perm = permutations[perm_index]\n",
    "        for item_index in range(num_items):\n",
    "            for feature_index in perm:  # Use the permutation directly\n",
    "                if matrix[item_index, feature_index - 1] == 1:  # Adjust for 0-based indexing\n",
    "                    signature_matrix[perm_index, item_index] = min(signature_matrix[perm_index, item_index], feature_index)\n",
    "                    break  # Stop after the first 1 is found\n",
    "    \n",
    "    return signature_matrix\n",
    "\n",
    "# Generate the signature matrix\n",
    "signature_matrix = minhashing(input_matrix, permutations)\n",
    "\n",
    "print(\"\\nSignature Matrix from Minhashing:\")\n",
    "print(signature_matrix)\n",
    "\n",
    "# Step 5: Calculate Jaccard similarity from the signature matrix\n",
    "def signature_jaccard_similarity(signature_matrix):\n",
    "    num_items = signature_matrix.shape[1]\n",
    "    similarity_matrix = np.zeros((num_items, num_items))\n",
    "    \n",
    "    for i in range(num_items):\n",
    "        for j in range(i + 1, num_items):\n",
    "            # Calculate intersection and union of signatures\n",
    "            intersection = np.sum(signature_matrix[:, i] == signature_matrix[:, j])\n",
    "            union = signature_matrix.shape[0]  # Total number of permutations\n",
    "            similarity = intersection / union\n",
    "            similarity_matrix[i, j] = similarity\n",
    "            similarity_matrix[j, i] = similarity  # Symmetric\n",
    "            \n",
    "    return similarity_matrix\n",
    "\n",
    "# Calculate Jaccard similarity from the signature matrix\n",
    "signature_jaccard_matrix = signature_jaccard_similarity(signature_matrix)\n",
    "print(\"\\nJaccard Similarity Matrix from Signature Matrix:\")\n",
    "print(signature_jaccard_matrix)\n",
    "\n",
    "# Step 6: Compare the Jaccard similarities\n",
    "print(\"\\nComparison of Jaccard Similarities:\")\n",
    "for i in range(input_jaccard_matrix.shape[0]):\n",
    "    for j in range(i + 1, input_jaccard_matrix.shape[1]):\n",
    "        print(f\"Document {i + 1} & Document {j + 1} - Input: {input_jaccard_matrix[i, j]:.4f}, Signature: {signature_jaccard_matrix[i, j]:.4f}\")\n",
    "\n",
    "# Conclusion on Minhashing\n",
    "print(\"\\nConclusion:\")\n",
    "print(\"Minhashing provides an approximation of Jaccard similarity. The effectiveness of Minhashing depends on the number of permutations used. More permutations generally yield better approximations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "60dc0edf",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 7 is out of bounds for axis 0 with size 7",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 71\u001b[0m\n\u001b[0;32m     68\u001b[0m original_sim \u001b[38;5;241m=\u001b[39m original_jaccard(input_matrix)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# 生成签名矩阵\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m sig_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_signatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpermutations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# 计算签名相似度\u001b[39;00m\n\u001b[0;32m     74\u001b[0m signature_sim \u001b[38;5;241m=\u001b[39m signature_similarity(sig_matrix)\n",
      "Cell \u001b[1;32mIn[42], line 41\u001b[0m, in \u001b[0;36mgenerate_signatures\u001b[1;34m(matrix, permutations)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_cols):\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m fixed_perm:\n\u001b[1;32m---> 41\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mmatrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     42\u001b[0m             sig_matrix[p_idx, col] \u001b[38;5;241m=\u001b[39m row\n\u001b[0;32m     43\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 7 is out of bounds for axis 0 with size 7"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "# 输入矩阵定义\n",
    "input_matrix = np.array([\n",
    "    [1, 0, 1, 0],\n",
    "    [0, 0, 1, 1],\n",
    "    [1, 1, 0, 1],\n",
    "    [0, 1, 0, 0],\n",
    "    [1, 0, 1, 1],\n",
    "    [1, 0, 0, 0],\n",
    "    [0, 1, 0, 1]\n",
    "])\n",
    "\n",
    "# 修正排列函数（处理无效行号并补全）\n",
    "def fix_permutation(perm, n_rows=7):\n",
    "    valid = [min(p-1, n_rows-1) if p > n_rows else p for p in perm] # 处理无效行号\n",
    "    all_rows = set(range(n_rows))\n",
    "    remaining = sorted(all_rows - set(valid))\n",
    "    return valid + remaining\n",
    "\n",
    "# 原始Jaccard计算\n",
    "def original_jaccard(matrix):\n",
    "    cols = matrix.shape[1]\n",
    "    results = {}\n",
    "    for (i,j) in combinations(range(cols), 2):\n",
    "        intersect = np.sum(np.logical_and(matrix[:,i], matrix[:,j]))\n",
    "        union = np.sum(np.logical_or(matrix[:,i], matrix[:,j]))\n",
    "        results[(i,j)] = intersect / union if union !=0 else 0\n",
    "    return results\n",
    "\n",
    "# MinHash签名生成\n",
    "def generate_signatures(matrix, permutations):\n",
    "    n_cols = matrix.shape[1]\n",
    "    sig_matrix = np.zeros((len(permutations), n_cols), dtype=int)\n",
    "    \n",
    "    for p_idx, perm in enumerate(permutations):\n",
    "        fixed_perm = fix_permutation(perm)\n",
    "        for col in range(n_cols):\n",
    "            for row in fixed_perm:\n",
    "                if matrix[row, col] == 1:\n",
    "                    sig_matrix[p_idx, col] = row\n",
    "                    break\n",
    "    return sig_matrix\n",
    "\n",
    "# 签名相似度计算\n",
    "def signature_similarity(sig_matrix):\n",
    "    n_cols = sig_matrix.shape[1]\n",
    "    results = {}\n",
    "    for (i,j) in combinations(range(n_cols), 2):\n",
    "        matches = np.sum(sig_matrix[:,i] == sig_matrix[:,j])\n",
    "        results[(i,j)] = matches / sig_matrix.shape[0]\n",
    "    return results\n",
    "\n",
    "# 主程序\n",
    "if __name__ == \"__main__\":\n",
    "    permutations = np.array([\n",
    "        [4, 3, 5, 2],\n",
    "        [2, 7, 1, 5],\n",
    "        [6, 1, 4, 3],\n",
    "        [1, 5, 6, 7],\n",
    "        [5, 2, 2, 1],\n",
    "        [3, 6, 7, 4],\n",
    "        [7, 4, 3, 6]\n",
    "    ])\n",
    "\n",
    "    # 计算原始相似度\n",
    "    original_sim = original_jaccard(input_matrix)\n",
    "    \n",
    "    # 生成签名矩阵\n",
    "    sig_matrix = generate_signatures(input_matrix, permutations)\n",
    "    \n",
    "    # 计算签名相似度\n",
    "    signature_sim = signature_similarity(sig_matrix)\n",
    "\n",
    "    # 结果输出\n",
    "    print(\"原始Jaccard相似度:\")\n",
    "    for pair, sim in original_sim.items():\n",
    "        print(f\"列{pair[0]}-列{pair[1]}: {sim:.2f}\")\n",
    "\n",
    "    print(\"\\nMinhash估计相似度:\")\n",
    "    for pair, sim in signature_sim.items():\n",
    "        print(f\"列{pair[0]}-列{pair[1]}: {sim:.2f}\")\n",
    "\n",
    "    # 签名矩阵打印\n",
    "    print(\"\\n生成的签名矩阵:\")\n",
    "    print(\"哈希函数 | 列0 列1 列2 列3\")\n",
    "    print(\"---------------------------\")\n",
    "    for i, row in enumerate(sig_matrix):\n",
    "        print(f\"   {i+1}    |\", \"  \".join(map(str, row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "128107ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Matrix Jaccard Similarity:\n",
      "+----------+----------+----------+----------+----------+----------+----------+\n",
      "|   Item 0 |   Item 1 |   Item 2 |   Item 3 |   Item 4 |   Item 5 |   Item 6 |\n",
      "+==========+==========+==========+==========+==========+==========+==========+\n",
      "|   1.0000 |   0.3333 |   0.2500 |   0.0000 |   0.6667 |   0.5000 |   0.0000 |\n",
      "+----------+----------+----------+----------+----------+----------+----------+\n",
      "|   0.3333 |   1.0000 |   0.2500 |   0.0000 |   0.6667 |   0.0000 |   0.3333 |\n",
      "+----------+----------+----------+----------+----------+----------+----------+\n",
      "|   0.2500 |   0.2500 |   1.0000 |   0.3333 |   0.5000 |   0.3333 |   0.6667 |\n",
      "+----------+----------+----------+----------+----------+----------+----------+\n",
      "|   0.0000 |   0.0000 |   0.3333 |   1.0000 |   0.0000 |   0.0000 |   0.5000 |\n",
      "+----------+----------+----------+----------+----------+----------+----------+\n",
      "|   0.6667 |   0.6667 |   0.5000 |   0.0000 |   1.0000 |   0.3333 |   0.2500 |\n",
      "+----------+----------+----------+----------+----------+----------+----------+\n",
      "|   0.5000 |   0.0000 |   0.3333 |   0.0000 |   0.3333 |   1.0000 |   0.0000 |\n",
      "+----------+----------+----------+----------+----------+----------+----------+\n",
      "|   0.0000 |   0.3333 |   0.6667 |   0.5000 |   0.2500 |   0.0000 |   1.0000 |\n",
      "+----------+----------+----------+----------+----------+----------+----------+\n",
      "\n",
      "Signature Matrix:\n",
      "+----------+----------+----------+----------+----------+----------+----------+\n",
      "|   Perm 0 |   Perm 1 |   Perm 2 |   Perm 3 |   Perm 4 |   Perm 5 |   Perm 6 |\n",
      "+==========+==========+==========+==========+==========+==========+==========+\n",
      "|        4 |        1 |        4 |        1 |        2 |        3 |        3 |\n",
      "+----------+----------+----------+----------+----------+----------+----------+\n",
      "|        2 |        1 |        3 |        6 |        1 |        4 |        3 |\n",
      "+----------+----------+----------+----------+----------+----------+----------+\n",
      "|        2 |        2 |        1 |        1 |        1 |        3 |        4 |\n",
      "+----------+----------+----------+----------+----------+----------+----------+\n",
      "|        3 |        7 |        1 |        5 |        2 |        6 |        4 |\n",
      "+----------+----------+----------+----------+----------+----------+----------+\n",
      "|        2 |        1 |        3 |        1 |        1 |        3 |        3 |\n",
      "+----------+----------+----------+----------+----------+----------+----------+\n",
      "|        4 |        2 |        6 |        1 |        5 |        3 |        7 |\n",
      "+----------+----------+----------+----------+----------+----------+----------+\n",
      "|        2 |        5 |        1 |        5 |        1 |        4 |        4 |\n",
      "+----------+----------+----------+----------+----------+----------+----------+\n",
      "\n",
      "Signature Matrix Jaccard Similarity:\n",
      "+----------+----------+----------+----------+----------+----------+----------+\n",
      "|   Item 0 |   Item 1 |   Item 2 |   Item 3 |   Item 4 |   Item 5 |   Item 6 |\n",
      "+==========+==========+==========+==========+==========+==========+==========+\n",
      "|   1.0000 |   0.2857 |   0.2857 |   0.1429 |   0.5714 |   0.4286 |   0.0000 |\n",
      "+----------+----------+----------+----------+----------+----------+----------+\n",
      "|   0.2857 |   1.0000 |   0.2857 |   0.0000 |   0.7143 |   0.0000 |   0.4286 |\n",
      "+----------+----------+----------+----------+----------+----------+----------+\n",
      "|   0.2857 |   0.2857 |   1.0000 |   0.2857 |   0.5714 |   0.4286 |   0.5714 |\n",
      "+----------+----------+----------+----------+----------+----------+----------+\n",
      "|   0.1429 |   0.0000 |   0.2857 |   1.0000 |   0.0000 |   0.0000 |   0.4286 |\n",
      "+----------+----------+----------+----------+----------+----------+----------+\n",
      "|   0.5714 |   0.7143 |   0.5714 |   0.0000 |   1.0000 |   0.2857 |   0.2857 |\n",
      "+----------+----------+----------+----------+----------+----------+----------+\n",
      "|   0.4286 |   0.0000 |   0.4286 |   0.0000 |   0.2857 |   1.0000 |   0.0000 |\n",
      "+----------+----------+----------+----------+----------+----------+----------+\n",
      "|   0.0000 |   0.4286 |   0.5714 |   0.4286 |   0.2857 |   0.0000 |   1.0000 |\n",
      "+----------+----------+----------+----------+----------+----------+----------+\n",
      "\n",
      "Comparison:\n",
      "Item 0-0: Input Jaccard=1.0000, Signature Jaccard=1.0000\n",
      "Item 0-1: Input Jaccard=0.3333, Signature Jaccard=0.2857\n",
      "Item 0-2: Input Jaccard=0.2500, Signature Jaccard=0.2857\n",
      "Item 0-3: Input Jaccard=0.0000, Signature Jaccard=0.1429\n",
      "Item 0-4: Input Jaccard=0.6667, Signature Jaccard=0.5714\n",
      "Item 0-5: Input Jaccard=0.5000, Signature Jaccard=0.4286\n",
      "Item 0-6: Input Jaccard=0.0000, Signature Jaccard=0.0000\n",
      "Item 1-0: Input Jaccard=0.3333, Signature Jaccard=0.2857\n",
      "Item 1-1: Input Jaccard=1.0000, Signature Jaccard=1.0000\n",
      "Item 1-2: Input Jaccard=0.2500, Signature Jaccard=0.2857\n",
      "Item 1-3: Input Jaccard=0.0000, Signature Jaccard=0.0000\n",
      "Item 1-4: Input Jaccard=0.6667, Signature Jaccard=0.7143\n",
      "Item 1-5: Input Jaccard=0.0000, Signature Jaccard=0.0000\n",
      "Item 1-6: Input Jaccard=0.3333, Signature Jaccard=0.4286\n",
      "Item 2-0: Input Jaccard=0.2500, Signature Jaccard=0.2857\n",
      "Item 2-1: Input Jaccard=0.2500, Signature Jaccard=0.2857\n",
      "Item 2-2: Input Jaccard=1.0000, Signature Jaccard=1.0000\n",
      "Item 2-3: Input Jaccard=0.3333, Signature Jaccard=0.2857\n",
      "Item 2-4: Input Jaccard=0.5000, Signature Jaccard=0.5714\n",
      "Item 2-5: Input Jaccard=0.3333, Signature Jaccard=0.4286\n",
      "Item 2-6: Input Jaccard=0.6667, Signature Jaccard=0.5714\n",
      "Item 3-0: Input Jaccard=0.0000, Signature Jaccard=0.1429\n",
      "Item 3-1: Input Jaccard=0.0000, Signature Jaccard=0.0000\n",
      "Item 3-2: Input Jaccard=0.3333, Signature Jaccard=0.2857\n",
      "Item 3-3: Input Jaccard=1.0000, Signature Jaccard=1.0000\n",
      "Item 3-4: Input Jaccard=0.0000, Signature Jaccard=0.0000\n",
      "Item 3-5: Input Jaccard=0.0000, Signature Jaccard=0.0000\n",
      "Item 3-6: Input Jaccard=0.5000, Signature Jaccard=0.4286\n",
      "Item 4-0: Input Jaccard=0.6667, Signature Jaccard=0.5714\n",
      "Item 4-1: Input Jaccard=0.6667, Signature Jaccard=0.7143\n",
      "Item 4-2: Input Jaccard=0.5000, Signature Jaccard=0.5714\n",
      "Item 4-3: Input Jaccard=0.0000, Signature Jaccard=0.0000\n",
      "Item 4-4: Input Jaccard=1.0000, Signature Jaccard=1.0000\n",
      "Item 4-5: Input Jaccard=0.3333, Signature Jaccard=0.2857\n",
      "Item 4-6: Input Jaccard=0.2500, Signature Jaccard=0.2857\n",
      "Item 5-0: Input Jaccard=0.5000, Signature Jaccard=0.4286\n",
      "Item 5-1: Input Jaccard=0.0000, Signature Jaccard=0.0000\n",
      "Item 5-2: Input Jaccard=0.3333, Signature Jaccard=0.4286\n",
      "Item 5-3: Input Jaccard=0.0000, Signature Jaccard=0.0000\n",
      "Item 5-4: Input Jaccard=0.3333, Signature Jaccard=0.2857\n",
      "Item 5-5: Input Jaccard=1.0000, Signature Jaccard=1.0000\n",
      "Item 5-6: Input Jaccard=0.0000, Signature Jaccard=0.0000\n",
      "Item 6-0: Input Jaccard=0.0000, Signature Jaccard=0.0000\n",
      "Item 6-1: Input Jaccard=0.3333, Signature Jaccard=0.4286\n",
      "Item 6-2: Input Jaccard=0.6667, Signature Jaccard=0.5714\n",
      "Item 6-3: Input Jaccard=0.5000, Signature Jaccard=0.4286\n",
      "Item 6-4: Input Jaccard=0.2500, Signature Jaccard=0.2857\n",
      "Item 6-5: Input Jaccard=0.0000, Signature Jaccard=0.0000\n",
      "Item 6-6: Input Jaccard=1.0000, Signature Jaccard=1.0000\n",
      "\n",
      "Is MinHashing a good approximation?\n",
      "Yes, MinHashing is a good approximation in this case. MinHashing works because the probability that two minhashes are equal is mathematically proven to equal the Jaccard similarity of the original sets.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Input matrix (7 items, 4 features)\n",
    "input_matrix = np.array([\n",
    "    [1, 0, 1, 0],\n",
    "    [0, 0, 1, 1],\n",
    "    [1, 1, 0, 1],\n",
    "    [0, 1, 0, 0],\n",
    "    [1, 0, 1, 1],\n",
    "    [1, 0, 0, 0],\n",
    "    [0, 1, 0, 1]\n",
    "])\n",
    "\n",
    "# Random permutations (7 permutations, 4 elements each)\n",
    "permutations = np.array([\n",
    "    [4, 3, 5, 2],\n",
    "    [2, 7, 1, 5],\n",
    "    [6, 1, 4, 3],\n",
    "    [1, 5, 6, 7],\n",
    "    [5, 2, 2, 1],\n",
    "    [3, 6, 7, 4],\n",
    "    [7, 4, 3, 6]\n",
    "])\n",
    "\n",
    "# Calculate Jaccard similarity for input matrix\n",
    "def jaccard_similarity(a, b):\n",
    "    intersection = np.logical_and(a, b).sum()\n",
    "    union = np.logical_or(a, b).sum()\n",
    "    return intersection / union if union != 0 else 0.0\n",
    "\n",
    "n_items = input_matrix.shape[0]\n",
    "input_jaccard = np.zeros((n_items, n_items))\n",
    "for i in range(n_items):\n",
    "    for j in range(n_items):\n",
    "        input_jaccard[i, j] = jaccard_similarity(input_matrix[i], input_matrix[j])\n",
    "\n",
    "print(\"Input Matrix Jaccard Similarity:\")\n",
    "print(tabulate(input_jaccard, headers=[f\"Item {i}\" for i in range(n_items)], \n",
    "               floatfmt=\".4f\", tablefmt=\"grid\"))\n",
    "\n",
    "# MinHashing to create signature matrix\n",
    "n_perm = permutations.shape[0]\n",
    "signature_matrix = np.full((n_items, n_perm), np.inf)\n",
    "\n",
    "for perm_idx in range(n_perm):\n",
    "    perm = permutations[perm_idx]\n",
    "    for item_idx in range(n_items):\n",
    "        item_vector = input_matrix[item_idx]\n",
    "        ones_indices = np.where(item_vector == 1)[0]\n",
    "        if ones_indices.size > 0:\n",
    "            min_hash = np.min(perm[ones_indices])\n",
    "            signature_matrix[item_idx, perm_idx] = min_hash\n",
    "\n",
    "print(\"\\nSignature Matrix:\")\n",
    "print(tabulate(signature_matrix, headers=[f\"Perm {i}\" for i in range(n_perm)], \n",
    "               floatfmt=\".0f\", tablefmt=\"grid\"))\n",
    "\n",
    "# Calculate Jaccard similarity for signature matrix\n",
    "signature_jaccard = np.zeros((n_items, n_items))\n",
    "for i in range(n_items):\n",
    "    for j in range(n_items):\n",
    "        sig_i = signature_matrix[i]\n",
    "        sig_j = signature_matrix[j]\n",
    "        intersection = np.equal(sig_i, sig_j).sum()\n",
    "        union = sig_i.shape[0]\n",
    "        signature_jaccard[i, j] = intersection / union if union != 0 else 0.0\n",
    "\n",
    "print(\"\\nSignature Matrix Jaccard Similarity:\")\n",
    "print(tabulate(signature_jaccard, headers=[f\"Item {i}\" for i in range(n_items)], \n",
    "               floatfmt=\".4f\", tablefmt=\"grid\"))\n",
    "\n",
    "# Compare results\n",
    "print(\"\\nComparison:\")\n",
    "for i in range(n_items):\n",
    "    for j in range(n_items):\n",
    "        print(f\"Item {i}-{j}: \"\n",
    "              f\"Input Jaccard={input_jaccard[i,j]:.4f}, \"\n",
    "              f\"Signature Jaccard={signature_jaccard[i,j]:.4f}\")\n",
    "\n",
    "# Conclusion\n",
    "print(\"\\nIs MinHashing a good approximation?\")\n",
    "if np.allclose(input_jaccard, signature_jaccard, atol=0.2):\n",
    "    print(\"Yes, MinHashing is a good approximation in this case. \"\n",
    "          \"MinHashing works because the probability that two minhashes are equal \"\n",
    "          \"is mathematically proven to equal the Jaccard similarity of the original sets.\")\n",
    "else:\n",
    "    print(\"No, MinHashing does not provide a good approximation here.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf91ecd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
